{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using human-generated neural reconstructions as our ground truth. The first step is to get rid of comments in the header of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_human_trajectories():\n",
    "    file_list = glob.glob(\"../data/human/*.swc\")\n",
    "    return file_list\n",
    "\n",
    "def remove_comments(fpaths, fnames):\n",
    "    \"\"\"SWC files start with comments, remove before proceeding\"\"\"\n",
    "    for i in range(len(fpaths)):\n",
    "\n",
    "        input = open(fpaths[i], \"r\")\n",
    "        outdir = \"../data/human_clean/\"\n",
    "        outdir = os.path.abspath(outdir)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        outfile = os.path.join(outdir, fnames[i])\n",
    "        output = open(outfile, \"w+\")\n",
    "\n",
    "        for line in input:\n",
    "            if not line.lstrip().startswith(\"#\"):\n",
    "                output.write(line)\n",
    "\n",
    "        input.close()\n",
    "        output.close()\n",
    "\n",
    "def main():\n",
    "    # get human trajectories\n",
    "    fnames = []\n",
    "    abs_paths = []\n",
    "    for root, dirs, fnames_ in os.walk(\"../data/human/\"):\n",
    "        fnames.extend(fnames_)\n",
    "        for f in fnames_:\n",
    "            relpath = os.path.join(root, f)\n",
    "            abs_path = os.path.abspath(relpath)\n",
    "            abs_paths.append(abs_path)\n",
    "\n",
    "    remove_comments(abs_paths, fnames)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to split each file into its component branches. The SWC files have the following columns:\n",
    "\n",
    "`node_id type x_coordinate y_coordinate z_coordinate radius parent_node`\n",
    "\n",
    "First, I convert the SWC file into a linked list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def file_to_linked_list(fpath: list):\n",
    "    \n",
    "    # https://stackoverflow.com/a/17756005/4212158\n",
    "    linked_list = defaultdict(list)\n",
    "    \n",
    "    input = open(fpath, \"r\")\n",
    "    for line in input:\n",
    "        # note: if the parent node is -1, then the child_node_id is the true identity of the root node\n",
    "        child_node_id, type_, x_coord, y_coord, z_coord, radius, parent_node = line.split()\n",
    "        new_node = (child_node_id, x_coord, y_coord, z_coord)\n",
    "        if len(new_node) != 4:\n",
    "            raise Exception(\"faulty node: {}\".format(new_node))\n",
    "        linked_list[parent_node].append(new_node)\n",
    "    \n",
    "    input.close()\n",
    "    return linked_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chopping  reconstructions into individual branches\n",
    "\n",
    "I start tracing the neuron starting at each root node, which by convention has a parent_node_id of -1. From each root node, I start to grow the branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_graph(fname: str, linked_list: dict):\n",
    "    \"\"\"take a single reconstruction, and chop it up at every fork\"\"\"\n",
    "    assert isinstance(linked_list, dict)\n",
    "    \n",
    "    root_nodes = linked_list[\"-1\"]\n",
    "    for i, root_node in enumerate(root_nodes):\n",
    "        print(\"scanning {} root node {} of {}\".format(fname, i, len(root_nodes)))\n",
    "        root_node_id, _x_coord, _y_coord, _z_coord = root_node\n",
    "\n",
    "        child_nodes = linked_list[root_node_id]\n",
    "        for j, child_node in enumerate(child_nodes):\n",
    "            print(\"starting child {} of {}\".format(j, len(child_nodes)))\n",
    "            child_node_id,  _x_coord, _y_coord, _z_coord = child_node\n",
    "            branch_name = \"_\".join([fname, \"root{}\".format(root_node_id), \"child{}\".format(child_node_id)])\n",
    "            grow_branch(linked_list, root_node_id, child_node_id, branch_name)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grow each branch until I encounter a fork. Forks are easy to find because the parent node will have more than one child. When the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-26-63511dd52195>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-63511dd52195>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def grow_branch(linked_list: dict, root_node_id: str, first_child_node_id: str, branch_name: str):\n",
    "    \"\"\"grow the branch until there's a fork\"\"\"\n",
    "    assert isinstance(linked_list, dict)\n",
    "    \n",
    "    # initialize the branch\n",
    "    print(\"new branch started: {}\".format(branch_name))\n",
    "    branch = [root_node_id, first_child_node_id]\n",
    "    \n",
    "    end_found = False\n",
    "    parent_node_id = first_child_node_id\n",
    "    while not end_found:\n",
    "        if (len(branch) % 10000000 == 0):\n",
    "            print(\"{} nodes processed\".format(len(branch)))\n",
    "        \n",
    "        if (len(branch) > 10*len(linked_list)):\n",
    "            raise Exception(\"this is growing out of control\")\n",
    "        try:\n",
    "            child_nodes = linked_list[parent_node_id]\n",
    "            if len(child_nodes) > 1: # fork found\n",
    "                print(\"fork found after {} nodes\".format(len(branch)))\n",
    "                save_branch_as_swc(branch, branch_name)\n",
    "                for i, child_node in enumerate(child_nodes):\n",
    "                    child_node_id, _x_coord, _y_coord, _z_coord = child_node\n",
    "                    child_branch_name = \"_\".join(branch_name, \"grandchild{}\".format(child_node_id))\n",
    "                    grow_branch(linked_list, parent_node_id, child_node)\n",
    "                end_found = True\n",
    "            elif len(child_nodes) == 0:  # no more children\n",
    "                print(\"end of branch {} found after {} nodes\".format(branch_name, len(branch)))\n",
    "                save_branch_as_swc(branch, branch_name)\n",
    "                end_found = True\n",
    "            else:\n",
    "                child_node = child_nodes[0]\n",
    "                child_node_id, _x_coord, _y_coord, _z_coord = child_node  # unpack node from list first\n",
    "                branch.append(child_node)  # should be just 1 node\n",
    "                parent_node_id = child_node_id\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save each branch as its own SWC file. Reminder, the column order convention is \n",
    "\n",
    "`node_id type x_coordinate y_coordinate z_coordinate radius parent_node`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_branch_as_swc(branch, branch_name):   \n",
    "    outdir = \"../data/human_splitted/\"\n",
    "    outdir = os.path.abspath(outdir)\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    outfile = os.path.join(outdir, branch_name, \".swc\")\n",
    "    print(\"saving SWC {}\".format(branch_name))\n",
    "    output = open(outfile, \"w+\")\n",
    "    \n",
    "    default_radius = 1.0\n",
    "    default_type = 3\n",
    "    \n",
    "    parent_node_id = \"-1\"\n",
    "    for i, node in enumerate(branch):\n",
    "        child_node_id, x, y, z = node\n",
    "        swc_line = \" \".join(child_node_id, default_type, x, y, z, default_radius, parent_node_id)\n",
    "        output.write(swc_line)\n",
    "        parent_node_id = child_node_id\n",
    "\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can go through the list of clean files and actually split everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 parsing 110_ZWX_LijLiu_06072018.ano.swc to linked list\n",
      "#0 splitting 110_ZWX_LijLiu_06072018.ano.swc to branches\n",
      "scanning 110_ZWX_LijLiu_06072018.ano.swc root node 0 of 929\n",
      "starting child 0 of 1\n",
      "new branch started: 110_ZWX_LijLiu_06072018.ano.swc_root5497882_child5497881\n",
      "[('5497880', '16633.000', '38326.000', '2461.000')]\n",
      "[('5497879', '16633.334', '38325.445', '2461.111')]\n",
      "[('5497878', '16634.666', '38324.668', '2461.889')]\n",
      "[('5497877', '16635.000', '38324.000', '2462.000')]\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-df8096ad3ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlinked_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_to_linked_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#{} splitting {} to branches\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mchop_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinked_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-70d8685ec901>\u001b[0m in \u001b[0;36mchop_graph\u001b[0;34m(fname, linked_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mchild_node_id\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0m_x_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_z_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mbranch_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"root{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_node_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_node_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mgrow_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinked_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_node_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_node_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-52b0cd53a8bd>\u001b[0m in \u001b[0;36mgrow_branch\u001b[0;34m(linked_list, root_node_id, first_child_node_id, branch_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mchild_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mchild_node_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_z_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild_node\u001b[0m \u001b[0;31m# unpack node from list first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mbranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_node\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# should be just 1 node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "clean_files = []\n",
    "fnames = []\n",
    "for root, dirs, fnames_ in os.walk(\"../data/human_clean/\"):\n",
    "        fnames.extend(fnames_)\n",
    "        for f in fnames_:\n",
    "            relpath = os.path.join(root, f)\n",
    "            abs_path = os.path.abspath(relpath)\n",
    "            clean_files.append(abs_path)\n",
    "assert len(clean_files) == len(fnames), \"# file paths and fnames don't match: {} and {}\".format(len(clean_files), len(fnames))\n",
    "\n",
    "#linked_lists = []\n",
    "for i in range(len(fnames)):\n",
    "    print(\"#{} parsing {} to linked list\".format(i, fnames[i]))\n",
    "    if i < 1: # TODO remove after debugging\n",
    "        linked_list = file_to_linked_list(clean_files[i])\n",
    "        print(\"#{} splitting {} to branches\".format(i, fnames[i]))\n",
    "        chop_graph(fnames[i], linked_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concerting SWC files into 3D images\n",
    "\n",
    "The SWC files can be rendered into volumetric JPEG images by Vaa3D plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
